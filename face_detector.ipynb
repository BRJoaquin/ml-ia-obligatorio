{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Detection Using Machine Learning Techniques\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This Jupyter Notebook presents an implementation of a face detection system using traditional Machine Learning techniques. Although deep learning-based approaches have become more prominent in recent years, the earlier methods retain their relevance due to their computational efficiency and robustness. A prime example of such an approach is the Viola-Jones face detector.\n",
    "\n",
    "The purpose of this project is to build face detectors from classifiers. Instead of directly working with pixels, we'll use features extracted from the images. Our main goal is to develop computationally light classifiers capable of determining whether a given image is a face.\n",
    "\n",
    "The project follows the following steps:\n",
    "\n",
    "1. **Preprocessing**: Define the initial treatment of images, such as normalization, scaling, and application of general transformations.\n",
    "2. **Features**: Define the process of extracting Haar features and building the feature matrix.\n",
    "3. **Classifiers**: Implement classification algorithms seen in the course, including ensemble techniques.\n",
    "4. **Model Evaluation**: Evaluate different classifiers using validation and evaluation techniques seen in the course.\n",
    "5. **Attentional Cascade**: Implement the cascading classification mechanism.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset consists of grayscale images, with pixel values ranging from 0 (black) to 255 (white). Of the `N` images, `p` are faces (positive examples) and `n` are backgrounds (negative examples).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Environment using Conda\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "1. **Python:** This project is written in Python, an interpreted high-level general-purpose programming language. Python must be installed on your machine. You can verify if Python is installed by typing `python --version` into your terminal. If Python is installed, this command should return a version number.\n",
    "\n",
    "2. **Conda:** Conda is an open-source package management system and environment management system. You should have Conda installed on your machine. To confirm, type `conda --version` in your terminal. If Conda is installed, this command will return a version number.\n",
    "\n",
    "If Python or Conda are not installed on your machine, you can download them from the [official Python website](https://www.python.org/) and [official Anaconda website](https://www.anaconda.com/products/distribution) respectively.\n",
    "\n",
    "## Conda Environment\n",
    "\n",
    "After ensuring that Python and Conda are installed, create a virtual environment for the project.\n",
    "\n",
    "1. **Create the environment**: We have provided an `environment.yml` file which contains a list of all the Python packages needed for the project. To create a new environment using this file, use the following command:\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "2. **Activate the environment**: After the new environment has been created, activate it with:\n",
    "\n",
    "```bash\n",
    "conda activate face_detection\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed for reproducibility\n",
    "SEED = 34\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this Jupyter notebook, we will embark on the first step of our Face Detection project: loading and exploring the dataset. This initial phase is crucial as it helps us to understand the data we're working with and to inform the subsequent steps in our machine learning workflow.\n",
    "\n",
    "The dataset consists of grayscale images, representing both faces (positive examples) and non-faces (negative examples). The positive examples are images of faces, while the negative examples are images taken from scenes that contain everything but faces. The images are all of the same size, and the faces in the positive examples are aligned and scaled to fit the images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset\n",
    "We will start by loading the dataset. The images are stored in a [pgm format](https://netpbm.sourceforge.net/doc/pgm.html), which is a simple format for grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FACES_DIR = \"data/train/face/\"\n",
    "TRAIN_BACKGROUND_DIR = \"data/train/non-face/\"\n",
    "TEST_FACES_DIR = \"data/test/face/\"\n",
    "TEST_BACKGROUND_DIR = \"data/test/non-face/\"\n",
    "\n",
    "\n",
    "def load_name_images(directory):\n",
    "    return [f for f in os.listdir(directory) if f.endswith('.pgm')]\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_faces = load_name_images(TRAIN_FACES_DIR)\n",
    "train_background = load_name_images(TRAIN_BACKGROUND_DIR)\n",
    "test_faces = load_name_images(TEST_FACES_DIR)\n",
    "test_background = load_name_images(TEST_BACKGROUND_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "After loading the data, we will perform an exploratory data analysis (EDA). This is where we examine the data, look for anomalies, study its structure, and visualize it through various kinds of plots. The goal of this stage is to find patterns, spot anomalies, or check assumptions with the help of summary statistics and graphical representations.\n",
    "\n",
    "The following tasks will be performed during the EDA:\n",
    "\n",
    "1. **Viewing the images**: We will view some of the face and non-face images to get an idea of what our data looks like.\n",
    "\n",
    "2. **Checking the balance of the dataset**: It is crucial to know if the data is balanced or imbalanced. If the data is imbalanced, it might impact the performance of our machine learning model, and we'll need to address this.\n",
    "\n",
    "3. **Basic Statistics**: We'll calculate some basic statistics to get a better sense of our data.\n",
    "\n",
    "4. **Visualizations**: We'll visualize some aspects of our data, like the distribution of the pixel values, which will help us understand the characteristics of the images.\n",
    "\n",
    "This initial exploration will help us get familiar with the dataset and gain valuable insights that will guide us in the rest of the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Images\n",
    "Let's start by viewing some of the images in our dataset. We'll use the `imshow()` and `imread()` functions from the `matplotlib` library to load and display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory, names):\n",
    "    return [plt.imread(directory + name) for name in tqdm(names, desc='Loading images from ' + directory)]\n",
    "\n",
    "# Load the trining images\n",
    "train_faces_images = load_images(TRAIN_FACES_DIR, train_faces)\n",
    "train_background_images = load_images(TRAIN_BACKGROUND_DIR, train_background)\n",
    "\n",
    "# Create the training set\n",
    "X_train = np.array(train_faces_images + train_background_images)\n",
    "# Create the labels (1 for faces, 0 for non-faces)\n",
    "y_train = np.array([1] * len(train_faces_images) + [0] * len(train_background_images))\n",
    "\n",
    "# Load the test images\n",
    "test_faces_images = load_images(TEST_FACES_DIR, test_faces)\n",
    "test_background_images = load_images(TEST_BACKGROUND_DIR, test_background)\n",
    "\n",
    "# Create the test set\n",
    "X_test = np.array(test_faces_images + test_background_images)\n",
    "# Create the labels (1 for faces, 0 for non-faces)\n",
    "y_test = np.array([1] * len(test_faces_images) + [0] * len(test_background_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 25 random images\n",
    "random_indices = np.random.choice(X_train.shape[0], size=25, replace=False)\n",
    "random_images = X_train[random_indices]\n",
    "random_labels = y_train[random_indices]\n",
    "\n",
    "# plot the 25 random images, with their labels\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(random_images[i], cmap='gray')\n",
    "    \n",
    "    ax.set_title('Face' if random_labels[i] else 'Non-face')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Balance of the Dataset\n",
    "\n",
    "Before proceeding with modeling, it's crucial to examine the balance of our dataset. A balanced dataset refers to one where the number of samples in each class are approximately equal. If our dataset is severely imbalanced, it might negatively impact the performance of our model, leading it to be biased towards the majority class.\n",
    "\n",
    "In the context of our face detection task, we need to ensure that we have an approximately equal number of face and non-face images. This step will ensure that our model gets enough exposure to both classes during training, leading to a more robust and generalizable model.\n",
    "\n",
    "Let's perform a check on our dataset to see how well balanced it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of each class\n",
    "counter = Counter(y_train)\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.title(\"Distribution of Classes in the Training Set\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.xticks(list(counter.keys()), ['Face', 'Background'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_percentage = (len(train_faces_images) / len(X_train)) * 100\n",
    "\n",
    "print(f\"Percentage of faces in the training set: {face_percentage:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset presents a mild imbalance, with 34.81% of the images being faces. This is not a severe imbalance, and we can proceed with the modeling step. Also, in next steps, we will use techniques to address this imbalance like use evaluation metrics that are robust to imbalanced datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics\n",
    "\n",
    "In the context of our face detection task, understanding the distribution of pixel values across our images can provide valuable insights for preprocessing steps and overall algorithm improvement. \n",
    "\n",
    "In grayscale images, pixel values range from 0 (black) to 255 (white). By analyzing these values, we can obtain information about aspects such as image brightness and contrast which are crucial for effective feature extraction and object detection.\n",
    "\n",
    "We can calculate a histogram to visualize the frequency distribution of pixel values. This, along with descriptive statistics such as mean, median, and standard deviation, can guide us towards appropriate preprocessing methods, for instance, brightness and contrast adjustments.\n",
    "\n",
    "Let's now proceed to analyze the distribution of pixel values in our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the array to 1D for histogram and statistics\n",
    "pixels = X_train.flatten()\n",
    "\n",
    "# Generate histogram\n",
    "plt.hist(pixels, bins=256, range=(0,256), color='gray')\n",
    "plt.title('Pixel Value Distribution')\n",
    "plt.xlabel('Pixel Value (0-255)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print basic statistics\n",
    "mean_value = np.mean(pixels)\n",
    "median_value = np.median(pixels)\n",
    "std_dev = np.std(pixels)\n",
    "\n",
    "print(f'Mean pixel value: {mean_value}')\n",
    "print(f'Median pixel value: {median_value}')\n",
    "print(f'Standard Deviation of pixel values: {std_dev}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "X_train_norm = [equalize_hist(image) for image in X_train]\n",
    "X_test_norm = [equalize_hist(image) for image in X_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
